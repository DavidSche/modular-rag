{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. caching\n",
    "1. tracing, logging and/or breaking down pipelines\n",
    "1. evals\n",
    "1. hypster stored_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. improvements - query enhancement, document summary, multiple documents \n",
    "1. optimizations - parallel runs, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. hypster registry?\n",
    "1. hypernodes with haystack backend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypster import HP, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def indexing_config(hp: HP):\n",
    "    from haystack.components.converters import PyPDFToDocument\n",
    "\n",
    "    converter = PyPDFToDocument()\n",
    "\n",
    "    from haystack.components.preprocessors import DocumentSplitter\n",
    "\n",
    "    split_by = hp.select([\"sentence\", \"word\", \"passage\", \"page\"], default=\"sentence\")\n",
    "    splitter = DocumentSplitter(split_by=split_by, split_length=hp.int_input(10), split_overlap=hp.int_input(2))\n",
    "\n",
    "    from haystack import Pipeline\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(\"loader\", converter)\n",
    "    pipeline.add_component(\"splitter\", splitter)\n",
    "    pipeline.connect(\"loader\", \"splitter\")\n",
    "\n",
    "\n",
    "indexing_config.save(\"configs/indexing.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def fast_embed(hp: HP):\n",
    "    from typing import Any, Dict, List\n",
    "\n",
    "    from fastembed import TextEmbedding\n",
    "\n",
    "    def get_model_dim(chosen_model: str, model_list: List[Dict[str, Any]]) -> int:\n",
    "        for model in model_list:\n",
    "            if model[\"model\"] == chosen_model:\n",
    "                return model[\"dim\"]\n",
    "        raise ValueError(f\"Model {chosen_model} not found in the list of supported models.\")\n",
    "    \n",
    "    from haystack_integrations.components.embedders.fastembed import (\n",
    "        FastembedDocumentEmbedder,\n",
    "        FastembedTextEmbedder,\n",
    "    )\n",
    "\n",
    "    meta_fileds_to_embed = [\"parent_doc_summary\"]\n",
    "\n",
    "    model = hp.select(\n",
    "        {\"bge-small\": \"BAAI/bge-small-en-v1.5\", \"mini-lm\": \"sentence-transformers/all-MiniLM-L6-v2\"},\n",
    "        default=\"mini-lm\",\n",
    "    )\n",
    "    import os\n",
    "\n",
    "    cpu_count = os.cpu_count() or 1\n",
    "    doc_embedder = FastembedDocumentEmbedder(\n",
    "        model=model, parallel=hp.int_input(cpu_count), meta_fields_to_embed=meta_fileds_to_embed\n",
    "    )\n",
    "    text_embedder = FastembedTextEmbedder(model=model)\n",
    "    embedding_dim = get_model_dim(model, TextEmbedding.list_supported_models())\n",
    "\n",
    "fast_embed.save(\"configs/fast_embed.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def jina_embed(hp: HP):\n",
    "    from haystack_integrations.components.embedders.jina import JinaDocumentEmbedder, JinaTextEmbedder\n",
    "\n",
    "    meta_fileds_to_embed = [\"parent_doc_summary\"]\n",
    "\n",
    "    model = hp.select({\"v3\": \"jina-embeddings-v3\", \"v2\": \"jina-embeddings-v2\"}, default=\"v3\")\n",
    "    late_chunking = hp.select([True, False], default=True, name=\"late_chunking\") if model == \"v3\" else False\n",
    "    doc_embedder = JinaDocumentEmbedder(\n",
    "        model=model,\n",
    "        batch_size=hp.int_input(16),\n",
    "        dimensions=hp.int_input(256),\n",
    "        task=\"retrieval.passage\",\n",
    "        late_chunking=late_chunking,\n",
    "        meta_fields_to_embed=meta_fileds_to_embed,\n",
    "    )\n",
    "    text_embedder = JinaTextEmbedder(model=model, dimensions=doc_embedder.dimensions, task=\"retrieval.query\")\n",
    "    embedding_dim = doc_embedder.dimensions\n",
    "\n",
    "jina_embed.save(\"configs/jina_embed.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def in_memory_retrieval(hp: HP):\n",
    "    from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever\n",
    "    from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "    embedding_similarity_function = hp.select([\"cosine\", \"dot_product\"], default=\"cosine\")\n",
    "    document_store = InMemoryDocumentStore(embedding_similarity_function=embedding_similarity_function)\n",
    "\n",
    "    from haystack.components.joiners.document_joiner import DocumentJoiner\n",
    "\n",
    "    join_mode = hp.select(\n",
    "        [\"distribution_based_rank_fusion\", \"concatenate\", \"merge\", \"reciprocal_rank_fusion\"],\n",
    "        default=\"distribution_based_rank_fusion\",\n",
    "    )\n",
    "    joiner = DocumentJoiner(join_mode=join_mode, top_k=hp.int_input(5))\n",
    "\n",
    "    from haystack import Pipeline\n",
    "\n",
    "    from src.haystack_utils import PassThroughDocumentsComponent, PassThroughTextComponent\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(\"query\", PassThroughTextComponent())\n",
    "    pipeline.add_component(\"bm25_retriever\", InMemoryBM25Retriever(document_store=document_store))\n",
    "    pipeline.add_component(\"embedding_retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "    pipeline.add_component(\"document_joiner\", joiner)\n",
    "    pipeline.add_component(\"retrieved_documents\", PassThroughDocumentsComponent())\n",
    "    pipeline.connect(\"query\", \"bm25_retriever\")\n",
    "    pipeline.connect(\"bm25_retriever\", \"document_joiner\")\n",
    "    pipeline.connect(\"embedding_retriever\", \"document_joiner\")\n",
    "    pipeline.connect(\"document_joiner\", \"retrieved_documents\")\n",
    "\n",
    "\n",
    "in_memory_retrieval.save(\"configs/in_memory_retrieval.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def qdrant_retrieval(hp: HP):\n",
    "    from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "    from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "\n",
    "    location = hp.text_input(\":memory:\")\n",
    "    embedding_similarity_function = hp.select([\"cosine\", \"dot_product\", \"l2\"], default=\"cosine\")\n",
    "\n",
    "    # if \"embedding_dim\" in hp.stored_values:\n",
    "    #     embedding_dim = hp.stored_value[\"embedding_dim\"]\n",
    "    # else:\n",
    "    #     embedding_dim = hp.int_input(256)\n",
    "\n",
    "    document_store = QdrantDocumentStore(\n",
    "        location=location, \n",
    "        recreate_index=True,\n",
    "        similarity=embedding_similarity_function,\n",
    "        #embedding_dim=embedding_dim,\n",
    "        on_disk=True,\n",
    "    )\n",
    "\n",
    "    embedding_retriever = QdrantEmbeddingRetriever(document_store=document_store, top_k=hp.int_input(5))\n",
    "\n",
    "    from haystack import Pipeline\n",
    "\n",
    "    from src.haystack_utils import PassThroughDocumentsComponent, PassThroughTextComponent\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(\"query\", PassThroughTextComponent())\n",
    "    pipeline.add_component(\"embedding_retriever\", embedding_retriever)\n",
    "    pipeline.add_component(\"retrieved_documents\", PassThroughDocumentsComponent())\n",
    "    pipeline.connect(\"embedding_retriever\", \"retrieved_documents\")\n",
    "\n",
    "\n",
    "qdrant_retrieval.save(\"configs/qdrant_retrieval.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def openai_llm(hp: HP):\n",
    "    from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "    model = hp.select(\n",
    "        {\"gpt-4o-mini\": \"gpt-4o-mini\", \"gpt-4o\": \"gpt-4o\", \"gpt-4o-latest\": \"gpt-4o-2024-08-06\"}, default=\"gpt-4o-mini\"\n",
    "    )\n",
    "    llm = OpenAIGenerator(model=model)\n",
    "\n",
    "\n",
    "openai_llm.save(\"configs/openai_llm.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def anthropic_llm(hp: HP):\n",
    "    from haystack_integrations.components.generators.anthropic import AnthropicGenerator\n",
    "\n",
    "    model = hp.select({\"haiku\": \"claude-3-haiku-20240307\", \"sonnet\": \"claude-3-5-sonnet-20240620\"}, default=\"haiku\")\n",
    "    llm = AnthropicGenerator(model=model)\n",
    "\n",
    "\n",
    "anthropic_llm.save(\"configs/anthropic_llm.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def llm(hp: HP):\n",
    "    from hypster import load\n",
    "\n",
    "    openai_llm = load(\"configs/openai_llm.py\")\n",
    "    anthropic_llm = load(\"configs/anthropic_llm.py\")\n",
    "\n",
    "    llm = hp.select(\n",
    "        {\"openai\": hp.propagate(openai_llm)[\"llm\"], \"anthropic\": hp.propagate(anthropic_llm)[\"llm\"]}, default=\"openai\"\n",
    "    )\n",
    "\n",
    "\n",
    "llm.save(\"configs/llm.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@config\n",
    "def hp_config(hp: HP):\n",
    "    from hypster import load\n",
    "\n",
    "    file_path = hp.text_input(\"data/raw/modular_rag.pdf\")\n",
    "    query = \"What is the use of BERT in this document?\"\n",
    "\n",
    "    indexing = load(\"configs/indexing.py\")\n",
    "    indexing_inputs = hp.propagate(indexing)\n",
    "    indexing_pipeline = indexing_inputs[\"pipeline\"]\n",
    "\n",
    "    fast_embed = load(\"configs/fast_embed.py\")\n",
    "    jina_embed = load(\"configs/jina_embed.py\")\n",
    "    embedder = hp.select({\"fastembed\": hp.propagate(fast_embed), \"jina\": hp.propagate(jina_embed)}, default=\"fastembed\")\n",
    "    indexing_pipeline.add_component(\"doc_embedder\", embedder[\"doc_embedder\"])\n",
    "\n",
    "    qdrant = load(\"configs/qdrant_retrieval.py\")\n",
    "    in_memory = load(\"configs/in_memory_retrieval.py\")\n",
    "    document_store = hp.select(\n",
    "        {\"in_memory\": hp.propagate(in_memory), \"qdrant\": hp.propagate(qdrant)}, default=\"in_memory\"\n",
    "    )\n",
    "\n",
    "    from haystack.components.writers import DocumentWriter\n",
    "    from haystack.document_stores.types import DuplicatePolicy\n",
    "\n",
    "    document_writer = DocumentWriter(document_store[\"document_store\"], policy=DuplicatePolicy.OVERWRITE)\n",
    "    indexing_pipeline.add_component(\"document_writer\", document_writer)\n",
    "\n",
    "    indexing_pipeline.connect(\"splitter\", \"doc_embedder\")\n",
    "    indexing_pipeline.connect(\"doc_embedder\", \"document_writer\")\n",
    "\n",
    "    pipeline = document_store[\"pipeline\"]\n",
    "    pipeline.add_component(\"text_embedder\", embedder[\"text_embedder\"])\n",
    "    pipeline.connect(\"query\", \"text_embedder\")\n",
    "    pipeline.connect(\"text_embedder\", \"embedding_retriever\")\n",
    "\n",
    "    llm = load(\"configs/llm.py\")\n",
    "    small_llm_model = hp.propagate(llm)\n",
    "    large_llm_model = hp.propagate(llm)\n",
    "\n",
    "    from haystack.components.builders import PromptBuilder\n",
    "\n",
    "    template = hp.text_input(\"\"\"\n",
    "    Given the following information, answer the question in one short sentence, \n",
    "    using the information provided in the documents. add an exact quote from the document to support your answer, \n",
    "    preferably with the keyword/s from the original question.\n",
    "\n",
    "    Context:\n",
    "    {% for document in documents %}\n",
    "        {{ document.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    Question: {{question}}\n",
    "    Answer:\n",
    "    Quote:\n",
    "    \"\"\")\n",
    "\n",
    "    pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "    pipeline.add_component(\"llm\", large_llm_model[\"llm\"])\n",
    "    pipeline.connect(\"retrieved_documents\", \"prompt_builder.documents\")\n",
    "    pipeline.connect(\"query\", \"prompt_builder.question\")\n",
    "    pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = hp_config(selections={\"large_llm_model\" : \"anthropic\", \"large_llm_model.model\": \"haiku\", \n",
    "                               \"document_store\" : \"in_memory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().update(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4fbe385a1e48e093738b8a518cfd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexing_pipeline.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 156/156 [00:01<00:00, 87.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 156}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexing_pipeline.run({\"loader\": {\"sources\": [file_path]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00, 193.20it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline.warm_up()\n",
    "response = pipeline.run({\"query\": {\"text\": query}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT is used in the document as part of the \"Dense Retriever\" to provide complex semantic representations of queries and documents.  \n",
      "Quote: \"Dense Retriever employs pre-trained language models (PLMs) to provide dense representations of queries and documents.\"\n"
     ]
    }
   ],
   "source": [
    "print(response[\"llm\"][\"replies\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
